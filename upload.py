import torch
import os
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
from huggingface_hub import login, upload_folder
import gc  # å¼•å…¥åƒåœ¾å›æ”¶

# ================= é…ç½®åŒºåŸŸ =================
# 1. Hugging Face ç™»å½• Token (ç¡®ä¿æ˜¯ Write æƒé™)
# å¦‚æœä½ å·²ç»æœ¬åœ° login() è¿‡ï¼Œè¿™é‡Œå¯ä»¥ç•™ç©ºï¼Œæˆ–è€…å–æ¶ˆæ³¨é‡Šå¡«å…¥
# login(token="hf_xxxxxxxxxxxxxxxxxxxxxxxx")

# 2. ä½ çš„ä»“åº“ ID
REPO_ID = "heizige/Qwen2.5-Social-3B-NB-Chat"

# 3. æœ¬åœ°è·¯å¾„é…ç½®
BASE_MODEL_PATH = "./models/Qwen/Qwen2.5-3B-Instruct"  # åŸºåº§æ¨¡å‹
ADAPTER_PATH = "./models/qwen_social_finetune_final"  # LoRA é€‚é…å™¨
MERGED_DIR = "./models/qwen_social_3b_merged_full"  # [ä¸´æ—¶] åˆå¹¶åå­˜æ”¾çš„å¹²å‡€ç›®å½•


# ===========================================
def merge_and_upload():
    print(f"ğŸš€ 1. [ä½å†…å­˜æ¨¡å¼] æ­£åœ¨åŠ è½½åŸºåº§æ¨¡å‹: {BASE_MODEL_PATH} ...")

    # === ä¿®æ”¹ç‚¹ 1: å¼ºåˆ¶ä½¿ç”¨ CPU åŠ è½½ï¼Œå¹¶å¼€å¯ low_cpu_mem_usage ===
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        torch_dtype=torch.float16,
        device_map="cpu",  # å¼ºåˆ¶ CPUï¼Œé˜²æ­¢ GPU æ˜¾å­˜ç¢å¯¼è‡´çš„é—®é¢˜
        low_cpu_mem_usage=True,  # é™ä½åŠ è½½æ—¶çš„å†…å­˜æ¶ˆè€—
        trust_remote_code=True
    )
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)

    print(f"ğŸš€ 2. æ­£åœ¨åŠ è½½ LoRA é€‚é…å™¨: {ADAPTER_PATH} ...")
    model = PeftModel.from_pretrained(base_model, ADAPTER_PATH, device_map="cpu")

    print("ğŸš€ 3. æ­£åœ¨æ‰§è¡Œåˆå¹¶ (Merge and Unload)...")
    model = model.merge_and_unload()

    # æ‰‹åŠ¨æ¸…ç†ä¸€ä¸‹å†…å­˜
    gc.collect()

    print(f"ğŸš€ 4. [å…³é”®] æ­£åœ¨ä»¥å°åˆ†å—ä¿å­˜æ¨¡å‹åˆ°: {MERGED_DIR} ...")

    # === ä¿®æ”¹ç‚¹ 2: è®¾ç½® max_shard_size="1GB" ===
    # é»˜è®¤æ˜¯ 5GBï¼Œæ”¹æˆ 1GB å¯ä»¥æå¤§é™ä½ä¿å­˜æ—¶çš„å†…å­˜å‹åŠ›
    model.save_pretrained(MERGED_DIR, max_shard_size="1GB", safe_serialization=True)
    tokenizer.save_pretrained(MERGED_DIR)

    if os.path.exists("README.md"):
        import shutil
        shutil.copy("README.md", os.path.join(MERGED_DIR, "README.md"))
        print("âœ… README.md å·²å¤åˆ¶")

    print(f"ğŸš€ 5. å¼€å§‹ä¸Šä¼ åˆ° HuggingFace: {REPO_ID} ...")

    upload_folder(
        folder_path=MERGED_DIR,
        repo_id=REPO_ID,
        repo_type="model",
        commit_message="Upload merged Qwen2.5-Social-3B model (1GB shards)"
    )

    print("\nğŸ‰ğŸ‰ğŸ‰ ä¸Šä¼ æˆåŠŸï¼")


if __name__ == "__main__":
    # ç¡®ä¿ä½ å·²ç»ç™»å½•
    login(token="xxxxxxxxxxxxxxxxxxxxxxxxx")  # æ›¿æ¢ä¸ºä½ çš„ Hugging Face Token
    merge_and_upload()