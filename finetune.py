import os
import torch
import json
import math
import matplotlib.pyplot as plt
from datasets import load_dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    TrainerCallback  # å¼•å…¥å›è°ƒåŸºç±»
)
from peft import LoraConfig, get_peft_model, TaskType

# å¼ºåˆ¶ç¦ç”¨ BnB
os.environ["PEFT_FORCE_NO_BITSANDBYTES"] = "1"

# ================= é…ç½®åŒºåŸŸ =================
CONFIG = {
    "model_path": "./models/Qwen/Qwen2.5-3B-Instruct",
    "train_file": "./data/train_test/train_cleaned.json",
    "test_file": "./data/train_test/test_cleaned.json",
    "output_dir": "./models/qwen_social_finetune_final",
    "max_length": 1024,
    "batch_size": 2,
    "gradient_accumulation_steps": 16,
    "learning_rate": 2e-4,
    "num_epochs":4,
    "save_steps": 100,
    "logging_steps": 10,  # å›¾è¡¨é‡‡æ ·çš„é¢‘ç‡
}


# ================= è‡ªå®šä¹‰è¿›åº¦æ¡å›è°ƒ =================
class PerEpochProgressCallback(TrainerCallback):
    """
    è‡ªå®šä¹‰å›è°ƒï¼šå®ç°æ¯ä¸ª Epoch å•ç‹¬æ˜¾ç¤ºç™¾åˆ†æ¯”è¿›åº¦
    """

    def __init__(self, total_epochs, steps_per_epoch):
        self.total_epochs = total_epochs
        self.steps_per_epoch = steps_per_epoch

    def on_step_end(self, args, state, control, **kwargs):
        # state.global_step æ˜¯å½“å‰æ€»æ­¥æ•° (ä¾‹å¦‚ 50)
        # è®¡ç®—å½“å‰åœ¨ç¬¬å‡ è½® (ä»1å¼€å§‹)
        current_step = state.global_step
        current_epoch = math.ceil(current_step / self.steps_per_epoch)

        # è®¡ç®—å½“å‰è½®å†…çš„æ­¥æ•° (1 ~ 98)
        steps_in_this_epoch = current_step % self.steps_per_epoch
        if steps_in_this_epoch == 0:
            steps_in_this_epoch = self.steps_per_epoch  # æ•´é™¤è¯´æ˜åˆšå¥½è·‘å®Œè¿™ä¸€è½®

        # è®¡ç®—ç™¾åˆ†æ¯”
        percentage = (steps_in_this_epoch / self.steps_per_epoch) * 100

        # æ‰“å°è¿›åº¦æ¡ (è¦†ç›–åŒä¸€è¡Œï¼Œå®ç°åŠ¨ç”»æ•ˆæœ)
        # æ ¼å¼ï¼š[Epoch 1/3] è¿›åº¦: 50/98 (51.02%) | Loss: xxxx

        # è·å–æœ€æ–°çš„ loss (å¦‚æœæœ‰)
        current_loss = "N/A"
        if state.log_history and "loss" in state.log_history[-1]:
            current_loss = f"{state.log_history[-1]['loss']:.4f}"

        print(
            f"\rğŸš€ [Epoch {current_epoch}/{self.total_epochs}] è¿›åº¦: {steps_in_this_epoch}/{self.steps_per_epoch} ({percentage:.2f}%) | æœ€æ–°Loss: {current_loss}",
            end="")


# ================= ç»˜å›¾å‡½æ•° =================
def plot_loss_curve(log_history, output_dir):
    steps = []
    losses = []
    for entry in log_history:
        if "loss" in entry:
            steps.append(entry["step"])
            losses.append(entry["loss"])

    if not steps:
        print("\nâš ï¸ æ²¡æœ‰æ•°æ®ï¼Œæ— æ³•ç»˜å›¾")
        return

    # ä¿å­˜åŸå§‹æ•°æ®
    with open(os.path.join(output_dir, "training_logs.json"), "w", encoding="utf-8") as f:
        json.dump(log_history, f, indent=2)

    # ç»˜å›¾
    plt.figure(figsize=(10, 6))
    plt.plot(steps, losses, marker='.', linestyle='-', color='#1f77b4', label='Training Loss')
    plt.title(f'Training Loss Curve (Epochs={CONFIG["num_epochs"]})')
    plt.xlabel('Global Steps')
    plt.ylabel('Loss')
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend()
    plt.savefig(os.path.join(output_dir, "loss_curve.png"))
    print(f"\nğŸ“ˆ Loss æ›²çº¿å·²ä¿å­˜è‡³: {os.path.join(output_dir, 'loss_curve.png')}")


# ================= ä¸»è®­ç»ƒé€»è¾‘ =================
def train():
    print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–...")

    # 1. å‡†å¤‡ Tokenizer & Model
    tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_path'], trust_remote_code=True, padding_side="right")
    if tokenizer.pad_token is None: tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        CONFIG['model_path'],
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    )
    model.gradient_checkpointing_enable()

    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM, inference_mode=False, r=16, lora_alpha=32, lora_dropout=0.05,
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    )
    model = get_peft_model(model, peft_config)

    # 2. å‡†å¤‡æ•°æ®
    def process_func(example):
        input_ids = tokenizer.apply_chat_template(example['messages'], tokenize=True, truncation=True,
                                                  max_length=CONFIG['max_length'], add_generation_prompt=False)
        return {"input_ids": input_ids, "labels": input_ids, "attention_mask": [1] * len(input_ids)}

    dataset = load_dataset("json", data_files={"train": CONFIG['train_file'], "test": CONFIG['test_file']})
    tokenized_dataset = dataset.map(process_func, remove_columns=dataset["train"].column_names)

    # 3. è®¡ç®—æ¯è½®æ­¥æ•° (ä¸ºäº†è¿›åº¦æ¡æ˜¾ç¤ºæ­£ç¡®)
    num_train_samples = len(tokenized_dataset["train"])
    steps_per_epoch = math.ceil(num_train_samples / (CONFIG['batch_size'] * CONFIG['gradient_accumulation_steps']))
    print(f"ğŸ“Š æ•°æ®é‡: {num_train_samples} | æ¯è½®æ­¥æ•°: {steps_per_epoch} | æ€»è½®æ•°: {CONFIG['num_epochs']}")

    # 4. åˆå§‹åŒ– Trainer
    trainer = Trainer(
        model=model,
        args=TrainingArguments(
            output_dir=CONFIG['output_dir'],
            per_device_train_batch_size=CONFIG['batch_size'],
            gradient_accumulation_steps=CONFIG['gradient_accumulation_steps'],
            learning_rate=CONFIG['learning_rate'],
            num_train_epochs=CONFIG['num_epochs'],
            save_steps=CONFIG['save_steps'],
            logging_steps=CONFIG['logging_steps'],
            fp16=True,
            optim="adamw_torch",
            ddp_find_unused_parameters=False,
            report_to="none",

            # ã€å…³é”®ã€‘ç¦ç”¨é»˜è®¤çš„ä¸‘é™‹è¿›åº¦æ¡ï¼Œä½¿ç”¨æˆ‘ä»¬è‡ªå·±çš„
            disable_tqdm=True
        ),
        train_dataset=tokenized_dataset["train"],
        eval_dataset=tokenized_dataset["test"],
        data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),

        # ã€å…³é”®ã€‘æ³¨å…¥æˆ‘ä»¬å†™çš„è¿›åº¦æ¡å›è°ƒ
        callbacks=[PerEpochProgressCallback(CONFIG['num_epochs'], steps_per_epoch)]
    )

    model.config.use_cache = False

    print("\n" + "=" * 40)
    print("ğŸ¤– å¼€å§‹è®­ç»ƒ (æŒ‰è½®æ¬¡æ˜¾ç¤ºè¿›åº¦)")
    print("=" * 40)

    trainer.train()

    print("\n\nâœ… è®­ç»ƒå®Œæˆï¼æ­£åœ¨ä¿å­˜...")
    trainer.save_model(CONFIG['output_dir'])
    tokenizer.save_pretrained(CONFIG['output_dir'])

    # ç»˜åˆ¶æ›²çº¿
    plot_loss_curve(trainer.state.log_history, CONFIG['output_dir'])


if __name__ == "__main__":
    train()