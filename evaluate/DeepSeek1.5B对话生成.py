import os
import json
import pandas as pd
from tqdm import tqdm
import ollama

# ================= é…ç½®åŒºåŸŸ =================
# Ollama æ¨¡å‹åç§°
OLLAMA_MODEL_NAME = "gpt-oss:20b"

# æ–‡ä»¶è·¯å¾„é…ç½®
EVAL_DATA_DIR = "D:/program/ai_program/nlp_end_done/evaluate/data/"
OUTPUT_DIR = "D:/program/ai_program/nlp_end_done/evaluate/results4/"  # ä¿®æ”¹ä¸º result3 ç›®å½•

SCENARIO_FILES = {
    "é•¿è¾ˆ": "elder_text.json",
    "å¥³å‹": "girl_text.json",
    "å¯¼å¸ˆ": "teacher_text.json",
    "é™Œç”Ÿäºº": "strange_text.json",
    "å¤«å¦»": "wife_text.json"
}

ROLE_PROMPTS = {
    "é•¿è¾ˆ": "ä½ æ˜¯ä¸€ä¸ªæƒ…å•†æé«˜çš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é•¿è¾ˆã€‘ã€‚è¯·ä¿æŒå°Šæ•¬ã€äº²åˆ‡çš„æ€åº¦ï¼Œå¹¶ä½¿ç”¨å¹½é»˜ã€æç¬‘æ„Ÿæ¥æ´»è·ƒæ°”æ°›ã€‚",
    "å¥³å‹": "ä½ æ˜¯ä¸€ä¸ªé£è¶£å¹½é»˜çš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€å¥³å‹ã€‘ã€‚å¯¹è¯å……æ»¡ä¸­å›½å¼å¹½é»˜å´åˆä¸å¤±æš§æ˜§ï¼Œé€‚å½“åè½¬ã€‚å…¶ä»–æ—¶å€™è¦æœ‰ç”œç¾çš„æ„Ÿè§‰ã€‚",
    "å¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä¸ªç†å·¥ç§‘ç ”ç©¶ç”Ÿï¼Œæƒ…å•†å¾ˆé«˜ï¼Œè¯´è¯æœ‰åˆ†å¯¸ã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€å¯¼å¸ˆã€‘ã€‚æ•´ä½“é£æ ¼è¦ï¼šå°Šæ•¬ã€ä¸“ä¸šã€ç¤¼è²Œä¸ºä¸»ï¼ŒåŒæ—¶å¯ä»¥é€‚åº¦å¹½é»˜ã€æœºæ™ºã€‚",
    "é™Œç”Ÿäºº": "ä½ æ˜¯ä¸€ä¸ªæœºæ™ºã€å¾—ä½“ã€æœ‰åˆ†å¯¸æ„Ÿçš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é™Œç”Ÿäººã€‘ã€‚ä¿æŒè½»æ¾ã€ç¤¼è²Œçš„æ€åº¦ï¼Œå¹¶ä½¿ç”¨é«˜æƒ…å•†å¹½é»˜æ¥åŒ–è§£å°´å°¬æˆ–æ‹‰è¿‘è·ç¦»ã€‚",
    "å¤«å¦»": "ä½ æ˜¯ä¸€ä¸ªæƒ…å•†åœ¨çº¿ã€é£è¶£æš–å¿ƒçš„ä¼´ä¾£ã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é…å¶ã€‘ã€‚å¯¹è¯å……æ»¡ç”Ÿæ´»çƒŸç«æ°”ï¼Œå…¼å…·å¹½é»˜è°ƒä¾ƒä¸æ¸©æŸ”åŒ…å®¹ã€‚"
}

# ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
os.makedirs(OUTPUT_DIR, exist_ok=True)


class DeepChat:
    def __init__(self, model_name):
        self.model_name = model_name

    def chat(self, messages):
        """è°ƒç”¨ Ollama ç”Ÿæˆå›å¤"""
        try:
            # options å¯ä»¥è®¾ç½® temperature ç­‰å‚æ•°ï¼Œè¿™é‡Œä¿æŒé»˜è®¤æˆ–æ ¹æ®éœ€è¦è°ƒæ•´
            response = ollama.chat(
                model=self.model_name,
                messages=messages,
                options={
                    "temperature": 0.7,
                    "top_p": 0.9,
                    "num_ctx": 4096 # ç¡®ä¿ä¸Šä¸‹æ–‡è¶³å¤Ÿé•¿
                }
            )
            return response["message"]["content"]
        except Exception as e:
            print(f"âš ï¸ Ollama è°ƒç”¨å‡ºé”™: {e}")
            return "Error: Generation Failed"


def format_history_for_excel(messages):
    """æ ¼å¼åŒ–å†å²æ¶ˆæ¯ç”¨äºExcelå±•ç¤º"""
    text = ""
    for msg in messages:
        role = "AI" if msg['role'] == 'assistant' else "ç”¨æˆ·"
        if msg['role'] == 'system': continue
        text += f"[{role}]: {msg['content']}\n"
    return text.strip()


def main():
    # åˆå§‹åŒ– Ollama èŠå¤©ç±»
    bot = DeepChat(OLLAMA_MODEL_NAME)
    print(f"ğŸš€ å·²è¿æ¥ Ollama æ¨¡å‹: {OLLAMA_MODEL_NAME}")

    for role_name, filename in SCENARIO_FILES.items():
        file_path = os.path.join(EVAL_DATA_DIR, filename)
        if not os.path.exists(file_path):
            print(f"âš ï¸ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            continue

        print(f"\nğŸ¤– æ­£åœ¨é€è½®è¯„ä¼°åœºæ™¯ (Ollama): ã€{role_name}ã€‘...")
        current_system_prompt = ROLE_PROMPTS.get(role_name, "ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚")

        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)

        excel_data = []

        # éå†æ¯ä¸€ä¸ªå¯¹è¯ Session
        for session_idx, item in enumerate(tqdm(data, desc=f"å¤„ç† {role_name}")):
            messages = item['messages']

            # === æ ¸å¿ƒé€»è¾‘ï¼šéå†å¯¹è¯ä¸­çš„æ¯ä¸€è½® ===
            for i in range(len(messages)):
                msg = messages[i]

                # å¦‚æœå½“å‰æ˜¯ User å‘è¨€ï¼Œä¸”ä¸‹ä¸€æ¡æ˜¯ AI å‘è¨€ï¼Œè¿™å°±æ˜¯ä¸€ä¸ªæµ‹è¯•ç‚¹
                if msg['role'] == 'user' and (i + 1 < len(messages)) and messages[i + 1]['role'] == 'assistant':

                    # 1. æˆªå–åˆ°å½“å‰ User çš„å†å²ä½œä¸ºè¾“å…¥
                    # æ³¨æ„ï¼šä¸ºäº†é¿å…ä¿®æ”¹åŸæ•°æ®ï¼Œè¿™é‡Œä½¿ç”¨ copy
                    raw_slice = messages[:i + 1]
                    input_msgs = [dict(m) for m in raw_slice]

                    # 2. å¼ºåˆ¶æ³¨å…¥ System Prompt
                    if input_msgs[0]['role'] == 'system':
                        input_msgs[0]['content'] = current_system_prompt
                    else:
                        input_msgs.insert(0, {"role": "system", "content": current_system_prompt})

                    # 3. æå–çœŸå€¼ (Ground Truth)
                    reference_answer = messages[i + 1]['content']

                    # 4. Ollama æ¨¡å‹ç”Ÿæˆ
                    model_reply = bot.chat(input_msgs)

                    # 5. è®¡ç®—å½“å‰æ˜¯ç¬¬å‡ è½® (ç²—ç•¥è®¡ç®—)
                    turn_index = (i + 1) // 2

                    excel_data.append({
                        "å¯¹è¯ID": session_idx + 1,
                        "è½®æ¬¡": f"ç¬¬ {turn_index} è½®",
                        "åœºæ™¯": role_name,
                        "å¯¹è¯å†å² (Context)": format_history_for_excel(input_msgs[:-1]),
                        "å½“å‰æé—®": msg['content'],
                        "ã€Ollamaæ¨¡å‹å›å¤ã€‘": model_reply,  # åˆ—ååŒºåˆ†
                        "ã€å‚è€ƒå›å¤ã€‘": reference_answer,
                        "è¯„åˆ† (1-5)": ""
                    })

        # ä¿å­˜ Excel
        df = pd.DataFrame(excel_data)
        # æ–‡ä»¶åä¿æŒä¸€è‡´æ€§ï¼Œæ–¹ä¾¿åç»­è„šæœ¬è¯»å–
        save_path = os.path.join(OUTPUT_DIR, f"gpt-oss:20bæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_{role_name}.xlsx")
        df.to_excel(save_path, index=False)
        print(f"âœ… è¡¨æ ¼å·²ç”Ÿæˆ: {save_path}")


if __name__ == "__main__":
    main()