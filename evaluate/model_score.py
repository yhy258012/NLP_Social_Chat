import pandas as pd
import json
import os
from openai import OpenAI
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
DEEPSEEK_API_KEY = "sk-b7a9f81ab82d44dc8ce89e97257e2c71"
DEEPSEEK_BASE_URL = "https://api.deepseek.com"

# 1. ä¿®æ”¹è¾“å…¥ç›®å½•ä¸º Ollama ç»“æœç›®å½•
INPUT_DIR = "D:/program/ai_program/nlp_end_done/evaluate/results3/"

# 2. ä¿®æ”¹ä¸º Ollama çš„æ–‡ä»¶ååˆ—è¡¨
FILES_TO_EVAL = [
    "Ollamaæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_é•¿è¾ˆ.xlsx",
    "Ollamaæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_å¥³å‹.xlsx",
    "Ollamaæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_å¯¼å¸ˆ.xlsx",
    "Ollamaæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_é™Œç”Ÿäºº.xlsx",
    "Ollamaæ¨¡å‹_å¤šè½®è¯„ä¼°è¡¨_å¤«å¦».xlsx"
]

# 3. å®Œæ•´çš„ Prompt æ˜ å°„ (è¯„åˆ†æ ‡å‡†)
ROLE_PROMPTS_MAP = {
    "é•¿è¾ˆ": "ä½ æ˜¯ä¸€ä¸ªæƒ…å•†æé«˜çš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é•¿è¾ˆã€‘ã€‚è¯·ä¿æŒå°Šæ•¬ã€äº²åˆ‡çš„æ€åº¦ï¼Œå¹¶ä½¿ç”¨å¹½é»˜ã€æç¬‘æ„Ÿæ¥æ´»è·ƒæ°”æ°›ã€‚",
    "å¥³å‹": "ä½ æ˜¯ä¸€ä¸ªé£è¶£å¹½é»˜çš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€å¥³å‹ã€‘ã€‚å¯¹è¯å……æ»¡ä¸­å›½å¼å¹½é»˜å´åˆä¸å¤±æš§æ˜§ï¼Œé€‚å½“åè½¬ã€‚å…¶ä»–æ—¶å€™è¦æœ‰ç”œç¾çš„æ„Ÿè§‰ã€‚",
    "å¯¼å¸ˆ": "ä½ æ˜¯ä¸€ä¸ªç†å·¥ç§‘ç ”ç©¶ç”Ÿï¼Œæƒ…å•†å¾ˆé«˜ï¼Œè¯´è¯æœ‰åˆ†å¯¸ã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€å¯¼å¸ˆã€‘ã€‚æ•´ä½“é£æ ¼è¦ï¼šå°Šæ•¬ã€ä¸“ä¸šã€ç¤¼è²Œä¸ºä¸»ï¼ŒåŒæ—¶å¯ä»¥é€‚åº¦å¹½é»˜ã€æœºæ™ºã€‚",
    "é™Œç”Ÿäºº": "ä½ æ˜¯ä¸€ä¸ªæœºæ™ºã€å¾—ä½“ã€æœ‰åˆ†å¯¸æ„Ÿçš„å·¥ç§‘å­¦ç”Ÿã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é™Œç”Ÿäººã€‘ã€‚ä¿æŒè½»æ¾ã€ç¤¼è²Œçš„æ€åº¦ï¼Œå¹¶ä½¿ç”¨é«˜æƒ…å•†å¹½é»˜æ¥åŒ–è§£å°´å°¬æˆ–æ‹‰è¿‘è·ç¦»ã€‚",
    "å¤«å¦»": "ä½ æ˜¯ä¸€ä¸ªæƒ…å•†åœ¨çº¿ã€é£è¶£æš–å¿ƒçš„ä¼´ä¾£ã€‚ä½ ç°åœ¨çš„å¯¹è¯å¯¹è±¡æ˜¯ä½ çš„ã€é…å¶ã€‘ã€‚å¯¹è¯å……æ»¡ç”Ÿæ´»çƒŸç«æ°”ï¼Œå…¼å…·å¹½é»˜è°ƒä¾ƒä¸æ¸©æŸ”åŒ…å®¹ã€‚"
}


# ================= è¯„åˆ†é€»è¾‘ =================
class JudgeModel:
    def __init__(self):
        self.client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=DEEPSEEK_BASE_URL)

    def evaluate(self, system_prompt, user_query, model_response, reference):
        # åˆ¤ç©ºä¿æŠ¤
        if not model_response or pd.isna(model_response):
            return {"score": 0, "reason": "é”™è¯¯ï¼šè¯»å–åˆ°çš„å›å¤ä¸ºç©º"}

        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸¥æ ¼çš„è§’è‰²æ‰®æ¼”è¯„ä¼°ä¸“å®¶ã€‚è¯·è¯„ä¼°ä»¥ä¸‹ AI å›å¤æ˜¯å¦ç¬¦åˆè®¾å®šçš„äººè®¾ã€‚

ã€è§’è‰²è®¾å®šã€‘
{system_prompt}

ã€ç”¨æˆ·æé—®ã€‘
{user_query}

ã€å¾…è¯„ä¼°å›å¤ã€‘
{model_response}

ã€å‚è€ƒå›å¤ã€‘
{reference}

è¯·åŸºäºä»¥ä¸‹æ ‡å‡†æ‰“åˆ† (1-5åˆ†)ï¼š
1åˆ†ï¼šä¸¥é‡åç¦»äººè®¾ï¼Œæˆ–é€»è¾‘é”™è¯¯ã€‚
2åˆ†ï¼šäººè®¾æ¨¡ç³Šï¼Œè¯­æ°”ç”Ÿç¡¬ã€‚
3åˆ†ï¼šåŸºæœ¬ç¬¦åˆäººè®¾ã€‚
4åˆ†ï¼šäººè®¾é²œæ˜ï¼Œè¯­æ°”è‡ªç„¶ã€‚
5åˆ†ï¼šå®Œç¾æ¼”ç»ï¼Œæƒ…å•†æé«˜ã€‚

è¯·åŠ¡å¿…åªè¿”å› JSON æ ¼å¼ï¼š
{{
    "score": è¯„åˆ†æ•°å­—(æ•´æ•°),
    "reason": "ç®€çŸ­ç†ç”±"
}}
"""
        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.0,
                max_tokens=200
            )
            content = response.choices[0].message.content
            clean_json = content.replace("```json", "").replace("```", "").strip()
            return json.loads(clean_json)
        except Exception as e:
            print(f"âš ï¸ API è¯·æ±‚å¤±è´¥: {e}")
            return {"score": 0, "reason": "API Error"}


# ================= ä¸»ç¨‹åº =================
def main():
    judge = JudgeModel()
    print(f"ğŸš€ å¼€å§‹è¯„ä¼° Ollama æ¨¡å‹æ•°æ® (Results3)...")

    for filename in FILES_TO_EVAL:
        file_path = os.path.join(INPUT_DIR, filename)
        if not os.path.exists(file_path):
            print(f"âš ï¸ è·³è¿‡: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
            continue

        print(f"\nğŸ“„ æ­£åœ¨æ‰¹æ”¹: {filename}")

        # è¯»å– Excel
        df = pd.read_excel(file_path)

        # åˆå§‹åŒ–è¯„åˆ†åˆ—
        if "LLMè¯„åˆ†" not in df.columns:
            df["LLMè¯„åˆ†"] = ""
            df["LLMè¯„è¯­"] = ""

        scores = []

        # éå†æ¯ä¸€è¡Œ
        for index, row in tqdm(df.iterrows(), total=df.shape[0], desc="è¯„åˆ†è¿›åº¦"):
            # æ–­ç‚¹ç»­ä¼ ï¼šå¦‚æœæœ‰æœ‰æ•ˆåˆ†æ•°åˆ™è·³è¿‡
            current_score = row.get("LLMè¯„åˆ†")
            if pd.notna(current_score) and current_score != "" and isinstance(current_score,
                                                                              (int, float)) and current_score > 0:
                scores.append(current_score)
                continue

            # === 1. è·å–äººè®¾ ===
            role_name = row.get("åœºæ™¯", "æœªçŸ¥çš„åœºæ™¯")
            sys_prompt = ROLE_PROMPTS_MAP.get(role_name, role_name)

            # === 2. å…³é”®ä¿®æ”¹ï¼šè¯»å–æ­£ç¡®çš„åˆ—å ===
            # è¿™é‡Œå¿…é¡»å¯¹åº”ä½ ç”Ÿæˆè„šæœ¬é‡Œå†™çš„åˆ—å "ã€Ollamaæ¨¡å‹å›å¤ã€‘"
            response = row.get("ã€Ollamaæ¨¡å‹å›å¤ã€‘")

            # å…¼å®¹æ€§ fallback
            if pd.isna(response):
                response = row.get("ã€æ¨¡å‹å›å¤ã€‘")

            # === Debug: æ‰“å°ç¬¬ä¸€æ¡çœ‹çœ‹æ˜¯å¦è¯»åˆ°äº† ===
            if index == 0:
                print(f"[DEBUG] æ­£åœ¨è¯»å–: {str(response)[:50]}...")

            query = row.get("å½“å‰æé—®", row.get("ç”¨æˆ·æé—®"))
            reference = row.get("ã€å‚è€ƒå›å¤ã€‘", row.get("ã€åŸå§‹å‚è€ƒå›å¤ã€‘"))

            # === 3. è°ƒç”¨ DeepSeek ===
            result = judge.evaluate(sys_prompt, query, response, reference)

            # å†™å…¥ç»“æœ
            df.at[index, "LLMè¯„åˆ†"] = result["score"]
            df.at[index, "LLMè¯„è¯­"] = result["reason"]

            if result["score"] > 0:
                scores.append(result["score"])

        # ä¿å­˜å› Excel
        df.to_excel(file_path, index=False)

        # æ‰“å°å¹³å‡åˆ†
        if scores:
            avg = sum(scores) / len(scores)
            print(f"âœ… {filename} å¹³å‡åˆ†: {avg:.2f}")
        else:
            print(f"âš ï¸ {filename} æ²¡æœ‰æœ‰æ•ˆåˆ†æ•°")


if __name__ == "__main__":
    main()